{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUbEmuvZJxlI"
   },
   "source": [
    "# PyTorch - homework 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efS07mO7J6AR"
   },
   "source": [
    "Please run the whole notebook with your code and submit the `.ipynb` file that includes your answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mJpzFaX0J6Zz",
    "outputId": "33e49695-d65f-4948-f0ea-057c6f3ad787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHomework by Ivan Christian, number: 1003056\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "student_name=\"Ivan Christian\"\n",
    "student_number=\"1003056\"\n",
    "\n",
    "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xDkwBg8LKQ_"
   },
   "source": [
    " ## Question 1 -- matrix multiplication\n",
    "\n",
    "Implement the following mathematical operation on both the CPU and GPU (use Google Colab or another cloud service if you don't have a GPU in your computer). Print:\n",
    "\n",
    "a) which type of GPU card you have and \n",
    "\n",
    "b) show the computation time for both CPU and GPU (using PyTorch). \n",
    "\n",
    "c) How much % fast is the GPU? \n",
    "\n",
    " The operation to implement is the dot product $C = B * A^T$\n",
    "\n",
    " whereby $A$ is a random matrix of size $30,000 \\times 1000$ and $B$ is a random matrix of size $3000 \\times 1000$. In addition to the required information asked above:\n",
    " \n",
    " d) please also print the resulting two $C$ matrices (they should be the same btw). \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BINvhm-PLKak"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of GPU card I have : GeForce RTX 2060\n",
      "cuda : tensor([[256.5879, 250.8252, 253.5668,  ..., 249.8878, 253.7228, 259.4933],\n",
      "        [244.5675, 242.5294, 247.5782,  ..., 240.8584, 245.0226, 250.9910],\n",
      "        [260.6516, 253.9894, 257.0881,  ..., 250.0958, 259.7038, 264.1951],\n",
      "        ...,\n",
      "        [242.7181, 236.7133, 241.8720,  ..., 237.2356, 240.3670, 249.9062],\n",
      "        [250.8562, 249.5258, 248.5147,  ..., 242.9029, 251.2433, 255.8506],\n",
      "        [244.7356, 249.8004, 244.7025,  ..., 239.4973, 245.0750, 253.0466]],\n",
      "       device='cuda:0'), shape : torch.Size([3000, 30000]), time_elapsed : 433.7928466796875\n",
      "cpu : tensor([[256.5877, 250.8253, 253.5670,  ..., 249.8877, 253.7227, 259.4933],\n",
      "        [244.5676, 242.5295, 247.5782,  ..., 240.8583, 245.0226, 250.9910],\n",
      "        [260.6516, 253.9894, 257.0880,  ..., 250.0957, 259.7039, 264.1952],\n",
      "        ...,\n",
      "        [242.7181, 236.7133, 241.8719,  ..., 237.2354, 240.3670, 249.9063],\n",
      "        [250.8561, 249.5259, 248.5147,  ..., 242.9029, 251.2434, 255.8505],\n",
      "        [244.7356, 249.8004, 244.7023,  ..., 239.4972, 245.0751, 253.0466]]), shape : torch.Size([3000, 30000]), time_elapsed : 462.6982421875\n",
      "GPU is 6.663409903842014% faster\n"
     ]
    }
   ],
   "source": [
    "# implement solution here\n",
    "import torch\n",
    "\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "\n",
    "print(f'Type of GPU card I have : {device_name}')\n",
    "\n",
    "## Dot product C = B* A.transpose\n",
    "\n",
    "A = torch.rand((30000, 1000))\n",
    "\n",
    "B = torch.rand((3000, 1000))\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "## GPU \n",
    "\n",
    "device = 'cuda'\n",
    "start.record()\n",
    "C = torch.matmul(B.to(device), torch.transpose(A, 0, 1).to(device))\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "gpu_time_elapsed = start.elapsed_time(end)\n",
    "\n",
    "print(f'{device} : {C}, shape : {C.shape}, time_elapsed : {gpu_time_elapsed}')\n",
    "\n",
    "## CPU\n",
    "\n",
    "device = 'cpu'\n",
    "start.record()\n",
    "C = torch.matmul(B.to(device), torch.transpose(A, 0, 1).to(device))\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "cpu_time_elapsed = start.elapsed_time(end)\n",
    "print(f'{device} : {C}, shape : {C.shape}, time_elapsed : {cpu_time_elapsed}')\n",
    "\n",
    "diff = (cpu_time_elapsed - gpu_time_elapsed)/ gpu_time_elapsed\n",
    "\n",
    "print(f'GPU is {diff*100}% faster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZJXmfT-yU3g"
   },
   "source": [
    "## Question 2 - grad\n",
    "\n",
    "\n",
    "Find the gradient (partial derivatives) of the function $g(w)$ below. \n",
    "\n",
    "Let  $w=[w_1,w_2]^T$\n",
    "\n",
    "Consider  $g(w)=2w_1w_2+w_2cos(w_1)$\n",
    "\n",
    "a) In PyTorch, compute:   $\\Delta_w g(w)$ \n",
    "\n",
    " and verify that $\\Delta_w g([\\pi,1])=[2,2*\\piâˆ’1]^T$ using the grad function, whereby the first position is the partial for $w_1$ and the second position is the partial for $w_2$. \n",
    "\n",
    "b) You can also write a function to manually calculate these partial derivatives! You can review your differential equations math at [here](https://www.wolframalpha.com/input/?i=derivative+y+cos%28x%29) and implement this is a second function below to verify that it comes to the same solution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLjz6_LKt4sc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autograd Partial Differentiation : (tensor([[2.0000],\n",
      "        [5.2832]]),)\n",
      "Manual partial differntiation : tensor([2.0000, 5.2832])\n"
     ]
    }
   ],
   "source": [
    "# write your solution here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pi = np.pi\n",
    "\n",
    "w = torch.tensor([pi,1.],requires_grad=True).reshape(-1,1)\n",
    "g_w = 2 * w[0] * w[1]  + w[1] * torch.cos(w[0])\n",
    "\n",
    "dw_auto = torch.autograd.grad(g_w, w)\n",
    "print(f'Autograd Partial Differentiation : {dw_auto}')\n",
    "\n",
    "# autograd\n",
    "\n",
    "# manual partial diff\n",
    "dw1 = 2 * w[1] - torch.sin(w[0])*w[1]\n",
    "dw2 = 2 * w[0] + torch.cos(w[0])\n",
    "\n",
    "dg_manual = torch.Tensor([dw1,dw2])\n",
    "print(f'Manual partial differntiation : {dg_manual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJwP6ur8LKjD"
   },
   "source": [
    "## Question 3 - dance hit song prediction\n",
    "\n",
    "Implement logistic regression in PyTorch for the following dance hit song prediction training dataset: \n",
    "https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
    "\n",
    " * Input variables: a number of audio features (most already standardized so don't worry about that)\n",
    " * Target variable: Topclass1030: \n",
    "   * 1 means it was a top 10 hit song; \n",
    "   * 0 means it never went above top 30 position.\n",
    "\n",
    "This dataset is derived from my paper on dance hit song prediction, for full description of features have a look at https://arxiv.org/abs/1905.08076. \n",
    "\n",
    "Print the evolution of the loss every few epochs and train the model until it converges. \n",
    " \n",
    " After training the logistic regression model, calculate the prediction accuracy on the test set: \n",
    " https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VyRP6bl8t4Wc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\chris\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([321])) that is different to the input size (torch.Size([321, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6652905344963074, \n",
      "Epoch: 500, Loss: 0.6133426427841187, \n",
      "Epoch: 1000, Loss: 0.593902051448822, \n",
      "Epoch: 1500, Loss: 0.5804840326309204, \n",
      "Epoch: 2000, Loss: 0.5704305768013, \n",
      "Epoch: 2500, Loss: 0.5625711679458618, \n",
      "Epoch: 3000, Loss: 0.5562218427658081, \n",
      "Epoch: 3500, Loss: 0.5509580969810486, \n",
      "Epoch: 4000, Loss: 0.5465038418769836, \n",
      "Epoch: 4500, Loss: 0.5426726937294006, \n",
      "Epoch: 5000, Loss: 0.5393335223197937, \n",
      "Epoch: 5500, Loss: 0.5363913178443909, \n",
      "Epoch: 6000, Loss: 0.5337753891944885, \n",
      "Epoch: 6500, Loss: 0.5314315557479858, \n",
      "Epoch: 7000, Loss: 0.5293176770210266, \n",
      "Epoch: 7500, Loss: 0.5274003148078918, \n",
      "Epoch: 8000, Loss: 0.5256525278091431, \n",
      "Epoch: 8500, Loss: 0.5240522027015686, \n",
      "Epoch: 9000, Loss: 0.5225812196731567, \n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "!pip install wget\n",
    "import wget\n",
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "train_url = 'https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv'\n",
    "test_url = 'https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv'\n",
    "\n",
    "\n",
    "if not os.path.exists('herremans_hit_1030training.csv') and not os.path.exists('herremans_hit_1030test.csv'):\n",
    "    train_data = wget.download(train_url) \n",
    "    test_data = wget.download(test_url)\n",
    "else:\n",
    "    train_data = 'herremans_hit_1030training.csv'\n",
    "    test_data = 'herremans_hit_1030test.csv'\n",
    "\n",
    "# load data\n",
    "\n",
    "train_data = pd.read_csv(train_data)\n",
    "test_data = pd.read_csv(test_data)\n",
    "\n",
    "# define logistic regression model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "  # input_size: Dimensionality of input feature vector.\n",
    "  # num_classes: The number of classes in the classification problem.\n",
    "    def __init__(self, input_size, num_classes):\n",
    "    # Always call the superclass (nn.Module) constructor first!\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# train model\n",
    "\n",
    "device = 'cuda'\n",
    "epochs = 9001\n",
    "\n",
    "num_outputs = 1\n",
    "num_input_features = 49\n",
    "\n",
    "lr_rate = 0.001\n",
    "loss_function = nn.BCELoss()\n",
    "logreg_clf = LogisticRegression(num_input_features, num_outputs).to(device)\n",
    "optimizer = torch.optim.SGD(logreg_clf.parameters(), lr=lr_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    x_data = torch.FloatTensor(train_data.loc[:, train_data.columns != 'Topclass1030'].values).to(device)\n",
    "    y_true = torch.FloatTensor(train_data['Topclass1030']).to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_pred = logreg_clf(x_data)\n",
    "    \n",
    "    loss = loss_function(y_pred, y_true).to(device) #calculate the loss\n",
    "    loss.backward() #backprop\n",
    "    optimizer.step()\n",
    "    if epoch % 500 == 0:\n",
    "        print (\"Epoch: {0}, Loss: {1}, \".format(epoch,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vw4yfGoGuChe"
   },
   "source": [
    "Run the below code to test the accuracy of your model on the training set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L88WmKtMt5gH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 44, True Negatives: 15\n",
      "False Positives: 14, False Negatives: 6\n",
      "Class specific accuracy of correctly predicting a hit song is 0.88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "test = pd.read_csv('herremans_hit_1030test.csv')\n",
    "labels = test.iloc[:,-1]\n",
    "test = test.drop('Topclass1030', axis=1)\n",
    "testdata = torch.Tensor(test.values).to(device)\n",
    "testlabels = torch.Tensor(labels.values).view(-1,1).to(device)\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, testdata.size()[0]): \n",
    "    Xtest = testdata[i]\n",
    "    y_hat = logreg_clf(Xtest)\n",
    "    if y_hat > 0.5:\n",
    "        prediction = 1\n",
    "    else: \n",
    "        prediction = 0\n",
    "\n",
    "    if (prediction == testlabels[i]):\n",
    "        if (prediction == 1):\n",
    "            TP += 1\n",
    "        else: \n",
    "            TN += 1\n",
    "\n",
    "    else:\n",
    "        if (prediction == 1):\n",
    "            FP += 1\n",
    "        else: \n",
    "            FN += 1\n",
    "\n",
    "print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
    "print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
    "rate = TP/(FN+TP)\n",
    "print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AI homework 1 - torch intro",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
